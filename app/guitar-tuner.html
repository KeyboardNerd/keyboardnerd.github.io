<html>

<head>
    <meta charset='utf-8' />
    <title>吉他调音</title>
</head>

<body>
    吉他调音<br />
    我希望能让这个应用在吵杂的情况下也能安稳使用<br />
    1. 得到麦克风权限(这个程序只有客户端，不信抓包看)<br/>
    <div id="microphone_allowed"></div><br />
    2. 检查麦克风的声音<br/>
    <div id="microphone_has_input"></div><br/>
    <canvas id="canvas" width="400" height="400"></canvas><br/>
    3. 看看是什么音阶<br/>
    <canvas id="frequency_canvas" width="400" height="400"></canvas><br/>
    4. 安静的环境下检测吉他弦准不准<br/>
    5. 吵杂的环境下检测吉他弦准不准<br/>
    6. 重写应用然后发布到各个平台!<br/>
</body>
<script>
    var microphone_allowed = document.getElementById("microphone_allowed")
    var microphone_has_input = document.getElementById("microphone_has_input")
    var canvas = document.getElementById('canvas');
    var canvasCtx = canvas.getContext('2d');
    var frequency_canvas = document.getElementById('frequency_canvas');
    var frequency_canvasCtx = frequency_canvas.getContext('2d');
    // request microphone
    navigator.mediaDevices.getUserMedia({ audio: true }).then((stream) => {
        console.log('success!')
        var AudioContext = window.AudioContext || window.webkitAudioContext;
        var audioContext = new AudioContext();
        var analyzer = audioContext.createAnalyser();
        var gain = audioContext.createGain();
        gain.gain.value = 0;
        var microphone = null;

        var frequencyBufferLength = analyzer.frequencyBinCount;
        var frequencyBuffer = new Float32Array(frequencyBufferLength);
        var waveBufferLength = 1024;
        var waveBuffer = new Float32Array(waveBufferLength);
        analyzer.fftSize = waveBufferLength;
        var filled = false
        const animation = (time) => {
            requestAnimationFrame(animation)
            try {
                analyzer.getFloatTimeDomainData(waveBuffer);
                canvasCtx.fillStyle = 'rgb(200, 200, 200)';
                canvasCtx.fillRect(0, 0, canvas.width, canvas.height);
                canvasCtx.lineWidth = 2;
                canvasCtx.strokeStyle = 'rgb(0, 0, 0)';
                canvasCtx.beginPath();

                var sliceWidth = canvas.width * 1.0 / waveBufferLength;
                var x = 0;

                for (var i = 0; i < waveBufferLength; i++) {
                    var v = waveBuffer[i] * 200.0;
                    var y = canvas.height / 2 + v;
                    if (waveBuffer[i] > 0.02 || waveBuffer[i] < -0.02) {
                        microphone_has_input.innerHTML = "你可能在说话"
                    } else {
                        microphone_has_input.innerHTML = "你好像没在说话"
                    }
                    if (i === 0) {
                        canvasCtx.moveTo(x, y);
                    } else {
                        canvasCtx.lineTo(x, y);
                    }
                    x += sliceWidth;
                }

                canvasCtx.lineTo(canvas.width, canvas.height / 2);
                canvasCtx.stroke();
            } catch (error){
                if (!filled){
                    canvasCtx.fillText("浏览器不支持波形图", 10, 50)
                    filled=true;
                }
            }

            analyzer.getFloatFrequencyData(frequencyBuffer);
            frequency_canvasCtx.fillStyle = 'rgb(200, 200, 200)';
            frequency_canvasCtx.fillRect(0, 0, frequency_canvas.width, frequency_canvas.height);
            const barWidth = (frequency_canvas.width / frequencyBufferLength) * 2.5;
            let posX = 0;
            for (let i = 0; i < frequencyBufferLength; i++) {
                const barHeight = (frequencyBuffer[i] + 140) * 2;
                frequency_canvasCtx.fillStyle = 'rgb(' + Math.floor(barHeight + 100) + ', 50, 50)';
                frequency_canvasCtx.fillRect(posX, frequency_canvas.height - barHeight / 2, barWidth, barHeight / 2);
                posX += barWidth + 1;
            }
        };


        microphone_allowed.innerHTML = "Yes, user gave the permission"
        microphone = audioContext.createMediaStreamSource(stream);
        microphone.connect(analyzer);
        analyzer.connect(gain);
        gain.connect(audioContext.destination);
        requestAnimationFrame(animation)
    }).catch((err) => {
        console.log(err);
        microphone_allowed.innerHTML = "No, user didn't give the permission"
    })
    console.log('done')
</script>

</html>